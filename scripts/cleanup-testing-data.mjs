import { createClient } from '@sanity/client'
import dotenv from 'dotenv'

dotenv.config({ path: '.env.local' })

const sanityClient = createClient({
  projectId: process.env.NEXT_PUBLIC_SANITY_PROJECT_ID,
  dataset: process.env.NEXT_PUBLIC_SANITY_DATASET,
  apiVersion: '2024-01-01',
  useCdn: false,
  token: process.env.SANITY_API_WRITE_TOKEN,
})

async function cleanup() {
  console.log('ğŸ§¹ Starting cleanup of TESTING dataset and related leads...\n')

  // STEP 1: Find all TESTING dataset leads
  const testingDatasetId = '0zCFr5Hp4BHeiAjnocfez4'
  const originalDatasetId = 'MR2mHETXVqBGL7XovVIhho'

  const testingLeads = await sanityClient.fetch(
    `*[_type == "dbrLead" && references("${testingDatasetId}")] { _id, firstName, secondName }`
  )

  console.log(`ğŸ” Found ${testingLeads.length} leads in TESTING dataset`)

  if (testingLeads.length > 0) {
    console.log('ğŸ—‘ï¸  Deleting TESTING dataset leads...')

    // Delete in batches of 50
    const BATCH_SIZE = 50
    let deleted = 0

    for (let i = 0; i < testingLeads.length; i += BATCH_SIZE) {
      const batch = testingLeads.slice(i, i + BATCH_SIZE)

      try {
        const transaction = sanityClient.transaction()
        batch.forEach(lead => {
          transaction.delete(lead._id)
        })
        await transaction.commit()

        deleted += batch.length
        console.log(`  âœ… Deleted batch ${Math.floor(i / BATCH_SIZE) + 1}/${Math.ceil(testingLeads.length / BATCH_SIZE)} (${deleted}/${testingLeads.length})`)
      } catch (error) {
        console.error(`  âŒ Batch failed:`, error.message)

        // Try one by one
        for (const lead of batch) {
          try {
            await sanityClient.delete(lead._id)
            deleted++
          } catch (err) {
            console.error(`    âŒ Failed to delete ${lead._id}`)
          }
        }
      }

      // Small delay
      await new Promise(resolve => setTimeout(resolve, 100))
    }

    console.log(`âœ… Deleted ${deleted} TESTING leads\n`)
  }

  // STEP 2: Remove datasetId from partially migrated leads
  const leadsWithDatasetId = await sanityClient.fetch(
    `*[_type == "dbrLead" && defined(datasetId)] { _id }`
  )

  if (leadsWithDatasetId.length > 0) {
    console.log(`ğŸ”§ Removing datasetId from ${leadsWithDatasetId.length} leads...`)

    for (const lead of leadsWithDatasetId) {
      try {
        await sanityClient.patch(lead._id).unset(['datasetId']).commit()
      } catch (err) {
        console.error(`  âŒ Failed to clean ${lead._id}`)
      }
    }

    console.log(`âœ… Cleaned datasetId references\n`)
  }

  // STEP 3: Delete dataset documents
  console.log('ğŸ—‘ï¸  Deleting dataset documents...')

  try {
    await sanityClient.delete(testingDatasetId)
    console.log('  âœ… Deleted TESTING dataset')
  } catch (err) {
    console.error('  âŒ Failed to delete TESTING dataset:', err.message)
  }

  try {
    await sanityClient.delete(originalDatasetId)
    console.log('  âœ… Deleted Original Dataset')
  } catch (err) {
    console.error('  âŒ Failed to delete Original Dataset:', err.message)
  }

  // STEP 4: Verify final state
  console.log('\nâœ¨ Cleanup complete! Verifying...')

  const finalCount = await sanityClient.fetch(`count(*[_type == "dbrLead"])`)
  const datasetsLeft = await sanityClient.fetch(`count(*[_type == "dataset"])`)

  console.log(`\nğŸ“Š Final state:`)
  console.log(`  Total leads: ${finalCount}`)
  console.log(`  Datasets: ${datasetsLeft}`)
  console.log(`\nâœ… Dashboard should now show ${finalCount} original leads`)
}

cleanup()
  .then(() => process.exit(0))
  .catch(err => {
    console.error('âŒ Cleanup failed:', err)
    process.exit(1)
  })
